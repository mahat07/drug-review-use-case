{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uZLZcitPi5_M"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.decomposition import NMF, LatentDirichletAllocation as LDA\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rj2_j-CjDvF",
        "outputId": "5d531907-bd23-4a0f-f9a3-fb23ce254883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure stopwords are downloaded\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o903tUkGjRjB",
        "outputId": "590a393c-5a05-4cbc-a573-b62714792eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv('/content/drive/My Drive/drug_cleanedtrain.csv')\n",
        "test_data = pd.read_csv('/content/drive/My Drive/drug_cleanedtest.csv')\n",
        "data = pd.concat([train_data, test_data])\n",
        "\n"
      ],
      "metadata": {
        "id": "1x2M22j6jS9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess text function\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''  # Handle non-string values\n",
        "    text = text.lower().strip()  # Lowercase and strip\n",
        "    text = re.sub(f'[{string.punctuation}]', '', text)  # Remove punctuation\n",
        "    text = re.sub('\\d+', '', text)  # Remove numbers\n",
        "    return text"
      ],
      "metadata": {
        "id": "J3gR2UyXkQxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "data['review'] = data['review'].apply(preprocess_text)\n",
        "data = data.fillna('')"
      ],
      "metadata": {
        "id": "M4ALCUALkfcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the labels\n",
        "# Ensure the LabelEncoders are fitted properly\n",
        "le_drug = LabelEncoder().fit(data['drugName'])\n",
        "le_condition = LabelEncoder().fit(data['condition'])\n"
      ],
      "metadata": {
        "id": "bZMbRalzkiBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X = data['review']\n",
        "y = data[['drugName', 'condition']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize vectorizers and fit on the training data\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=1.0, min_df=1, stop_words='english')\n",
        "count_vectorizer = CountVectorizer(max_df=1.0, min_df=1, stop_words='english')"
      ],
      "metadata": {
        "id": "0Zu7R-9fmqw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the vectorizers\n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
        "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
        "cv_train = count_vectorizer.fit_transform(X_train)\n",
        "cv_test = count_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "ZqYg5niomvNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Combine the features\n",
        "X_train_combined = hstack([tfidf_train, cv_train])\n",
        "X_test_combined = hstack([tfidf_test, cv_test])"
      ],
      "metadata": {
        "id": "rANg5QTEmxya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and pad sequences for CNN model\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "max_length = 500\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_length)\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_length)"
      ],
      "metadata": {
        "id": "l-DfHH-em-1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Import necessary modules\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Dropout, Flatten, Dense\n",
        "\n",
        "# Create the CNN model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=128, input_length=max_length),\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2), # Now MaxPooling1D is recognized\n",
        "    Dropout(0.5),\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2), # Now MaxPooling1D is recognized\n",
        "    Dropout(0.5),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_data=(X_test_padded, y_test))"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYxSRdx1nWtH",
        "outputId": "d9b4438d-8b32-462d-b8df-5f496987998f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m5377/5377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 157ms/step - accuracy: 0.9241 - loss: 97632715536334848.0000 - val_accuracy: 0.9252 - val_loss: 1993235773079420928.0000\n",
            "Epoch 2/5\n",
            "\u001b[1m5377/5377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m813s\u001b[0m 148ms/step - accuracy: 0.9239 - loss: 5078085656790433792.0000 - val_accuracy: 0.9252 - val_loss: 22504880963133112320.0000\n",
            "Epoch 3/5\n",
            "\u001b[1m5377/5377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m774s\u001b[0m 143ms/step - accuracy: 0.9246 - loss: nan - val_accuracy: 0.9252 - val_loss: nan\n",
            "Epoch 4/5\n",
            "\u001b[1m5377/5377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m795s\u001b[0m 142ms/step - accuracy: 0.9249 - loss: nan - val_accuracy: 0.9252 - val_loss: nan\n",
            "Epoch 5/5\n",
            "\u001b[1m5377/5377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m808s\u001b[0m 143ms/step - accuracy: 0.9246 - loss: nan - val_accuracy: 0.9252 - val_loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d8eea369ff0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.save('/content/drive/My Drive/drug_model.h5')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71KUFwaz0Df8",
        "outputId": "a1824847-b5a7-4525-a851-4a75d7f04a2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # Import from tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Import from tensorflow.keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import LatentDirichletAllocation, NMF\n"
      ],
      "metadata": {
        "id": "8teC5jioEpW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess text function\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''  # Handle non-string values\n",
        "    text = text.lower().strip()  # Lowercase and strip\n",
        "    text = re.sub(f'[{string.punctuation}]', '', text)  # Remove punctuation\n",
        "    text = re.sub('\\d+', '', text)  # Remove numbers\n",
        "    return text\n",
        "\n",
        "train_data['cleanedReview'] = train_data['review'].apply(preprocess_text)\n",
        "\n",
        "# Preprocess drug names to handle multiple names\n",
        "def preprocess_drug_names(drug_names):\n",
        "    return [name.strip() for name in drug_names.split(',')]\n",
        "\n",
        "# Create a mapping of conditions to drug names with frequencies\n",
        "def create_condition_to_drugs_mapping(df):\n",
        "    condition_to_drugs = {}\n",
        "    for condition, drugs in df.groupby('condition')['drugName']:\n",
        "        drug_counter = Counter()\n",
        "        for drug_list in drugs:\n",
        "            drug_counter.update(preprocess_drug_names(drug_list))\n",
        "        condition_to_drugs[condition.lower()] = drug_counter\n",
        "    return condition_to_drugs\n",
        "\n",
        "condition_to_drugs = create_condition_to_drugs_mapping(train_data)\n",
        "\n",
        "# Function to find drugs for a given condition\n",
        "def find_drugs_for_condition(condition, top_n=3):\n",
        "    condition = condition.lower().strip()  # Ensure consistency\n",
        "    drug_counter = condition_to_drugs.get(condition, Counter())\n",
        "\n",
        "    # Get the top N drugs based on frequency\n",
        "    top_drugs = drug_counter.most_common(top_n)\n",
        "    return [drug for drug, _ in top_drugs]\n",
        "\n",
        "# Function to get top reviews for a particular drug\n",
        "def get_top_reviews_for_drug(df, drug_name, top_n=5):\n",
        "    drug_reviews = df[df['drugName'].str.contains(drug_name, case=False, na=False)]\n",
        "    top_reviews = drug_reviews.nlargest(top_n, 'rating')[['review', 'rating']]\n",
        "    return top_reviews\n",
        "\n",
        "# Function to highlight words based on topics\n",
        "def highlight_words(text, words):\n",
        "    highlighted_text = text\n",
        "    for word in words:\n",
        "        highlighted_text = re.sub(f'\\\\b({word})\\\\b', r'**\\1**', highlighted_text, flags=re.IGNORECASE)\n",
        "    return highlighted_text\n",
        "\n",
        "# Function to extract topics using LDA and NMF\n",
        "def extract_topics(reviews, num_topics=2, num_words=5):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf = vectorizer.fit_transform(reviews)\n",
        "\n",
        "    # LDA\n",
        "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "    lda.fit(tfidf)\n",
        "    lda_words = []\n",
        "    for topic in lda.components_:\n",
        "        lda_words.append([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-num_words:]])\n",
        "\n",
        "    # NMF\n",
        "    nmf = NMF(n_components=num_topics, random_state=42)\n",
        "    nmf.fit(tfidf)\n",
        "    nmf_words = []\n",
        "    for topic in nmf.components_:\n",
        "        nmf_words.append([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-num_words:]])\n",
        "\n",
        "    return lda_words, nmf_words\n",
        "\n",
        "# Example usage to find top drugs for a condition\n",
        "condition = 'adhd'\n",
        "top_drugs_for_condition = find_drugs_for_condition(condition)\n",
        "print(\"Top drug names for condition\", condition, \":\", top_drugs_for_condition)\n",
        "\n",
        "# Example usage to get top 5 reviews for a drug\n",
        "drug_name = 'Adderall'\n",
        "top_reviews = get_top_reviews_for_drug(train_data, drug_name)\n",
        "print(\"Top reviews for drug\", drug_name, \":\\n\", top_reviews)\n",
        "\n",
        "# Extract topics\n",
        "reviews_list = top_reviews['review'].tolist()\n",
        "lda_words, nmf_words = extract_topics(reviews_list)\n",
        "\n",
        "print(\"LDA topic words:\", lda_words)\n",
        "print(\"NMF topic words:\", nmf_words)\n",
        "\n",
        "# Highlight words in reviews\n",
        "highlighted_reviews = [highlight_words(review, lda_words[0] + nmf_words[0]) for review in reviews_list]\n",
        "\n",
        "print(\"Highlighted reviews:\")\n",
        "for review in highlighted_reviews:\n",
        "    print(review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxDN10cpEj09",
        "outputId": "b79d43c5-4876-4c4f-f181-18b3c3e0041a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top drug names for condition adhd : ['lisdexamfetamine', 'vyvanse', 'methylphenidate']\n",
            "Top reviews for drug Adderall :\n",
            "                                                  review  rating\n",
            "2452                                            amazing      10\n",
            "3156  this medicine is amazing i used to always be t...      10\n",
            "4016  i am a 23 year old male 1lbs on adderall 2mg x...      10\n",
            "5781  started off with concerta in may 22 it was not...      10\n",
            "5936  i have narcolepsy and i take 2mg three times p...      10\n",
            "LDA topic words: [['2mg', 'xr', 'adderall', 'great', 'nap'], ['taking', 'started', 'like', 'adderall', 'amazing']]\n",
            "NMF topic words: [['long', 'nap', 'great', 'xr', 'adderall'], ['lot', 'care', 'ranging', 'like', 'amazing']]\n",
            "Highlighted reviews:\n",
            "amazing\n",
            "this medicine is amazing i used to always be the last one to turn in tests in high school now i take one in the morning and in about an hour feel like i am my true self with it i can process information clearly easily and very efficiently now i have no problems with writing essays answering indepth questions secondguessing myself i even found that i am a lot more confident with many things ranging from presentations to girls i also take much better care of myself throughout the day except when it comes to eating for i do experience the loss in appetite to describe it it is almost like an auto tuneup program except for your brain ****adderall**** is absolutely ****great**** for me\n",
            "i am a 23 year old male 1lbs on ****adderall**** **2mg** ****xr**** ****great**** tool motivation and selfesteem awesome boost focused and better moods persistent anxiety lessened some grogginess but manageable so **long** as you eat appropriately minor loss of appetite  been on strattera and lexapro in past no comparability to ****adderall**** ****xr****  absolutely recommend to others and parents\n",
            "started off with concerta in may 22 it was not effective at all switched over to ****adderall**** ****xr**** 1mg in july 22 for seven days as a starter dose then started ****adderall**** ****xr**** **2mg**  i noticed a considerable difference between the two medicines instantly i am able to focus for a very **long** period of time without being distracted my grades improved exceptionally i went from receiving grades below 55 now my lowest grade is 83 the benefits of this medicine do outweigh the side effects for me i noticed 20 minutes after taking ****adderall**** i have increased bowel movements lower libido and decreased appetite i stop taking ****adderall**** during breaks and **long** weekends the first day not on it i am extremely tired exercising and eating healthy helps\n",
            "i have narcolepsy and i take **2mg** three times per day of quick release tabs mornings are ****great**** but mid to late afternoon i tend to ****nap**** and then take my last dose after last ****nap**** ****adderall**** helps ****great**** for keeping me awake and alert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess text function\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''  # Handle non-string values\n",
        "    text = text.lower().strip()  # Lowercase and strip\n",
        "    text = re.sub(f'[{string.punctuation}]', '', text)  # Remove punctuation\n",
        "    text = re.sub('\\d+', '', text)  # Remove numbers\n",
        "    return text\n",
        "\n",
        "train_data['cleanedReview'] = train_data['review'].apply(preprocess_text)\n",
        "\n",
        "# Preprocess drug names to handle multiple names\n",
        "def preprocess_drug_names(drug_names):\n",
        "    return [name.strip() for name in drug_names.split(',')]\n",
        "\n",
        "# Create a mapping of conditions to drug names with frequencies\n",
        "def create_condition_to_drugs_mapping(df):\n",
        "    condition_to_drugs = {}\n",
        "    for condition, drugs in df.groupby('condition')['drugName']:\n",
        "        drug_counter = Counter()\n",
        "        for drug_list in drugs:\n",
        "            drug_counter.update(preprocess_drug_names(drug_list))\n",
        "        condition_to_drugs[condition.lower()] = drug_counter\n",
        "    return condition_to_drugs\n",
        "\n",
        "condition_to_drugs = create_condition_to_drugs_mapping(train_data)\n",
        "\n",
        "# Function to find drugs for a given condition\n",
        "def find_drugs_for_condition(condition, top_n=3):\n",
        "    condition = condition.lower().strip()  # Ensure consistency\n",
        "    drug_counter = condition_to_drugs.get(condition, Counter())\n",
        "\n",
        "    # Get the top N drugs based on frequency\n",
        "    top_drugs = drug_counter.most_common(top_n)\n",
        "    return [drug for drug, _ in top_drugs]\n",
        "\n",
        "# Function to get top reviews for a particular drug\n",
        "def get_top_reviews_for_drug(df, drug_name, top_n=5):\n",
        "    drug_reviews = df[df['drugName'].str.contains(drug_name, case=False, na=False)]\n",
        "    top_reviews = drug_reviews.nlargest(top_n, 'rating')[['review', 'rating']]\n",
        "    return top_reviews\n",
        "\n",
        "# Function to highlight words based on topics\n",
        "def highlight_words(text, words):\n",
        "    highlighted_text = text\n",
        "    for word in words:\n",
        "        highlighted_text = re.sub(f'\\\\b({word})\\\\b', r'<mark>\\1</mark>', highlighted_text, flags=re.IGNORECASE)\n",
        "    return highlighted_text\n",
        "\n",
        "# Function to extract topics using LDA and NMF\n",
        "def extract_topics(reviews, num_topics=2, num_words=5):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf = vectorizer.fit_transform(reviews)\n",
        "\n",
        "    # LDA\n",
        "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "    lda.fit(tfidf)\n",
        "    lda_words = []\n",
        "    for topic in lda.components_:\n",
        "        lda_words.append([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-num_words:]])\n",
        "\n",
        "    # NMF\n",
        "    nmf = NMF(n_components=num_topics, random_state=42)\n",
        "    nmf.fit(tfidf)\n",
        "    nmf_words = []\n",
        "    for topic in nmf.components_:\n",
        "        nmf_words.append([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-num_words:]])\n",
        "\n",
        "    return lda_words, nmf_words\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Get input from user\n",
        "    condition = input(\"Enter the condition: \").strip()\n",
        "    drug_name = input(\"Enter the drug name: \").strip()\n",
        "\n",
        "    # Find top drugs for the condition\n",
        "    top_drugs_for_condition = find_drugs_for_condition(condition)\n",
        "    print(\"Top drug names for condition\", condition, \":\", top_drugs_for_condition)\n",
        "\n",
        "    # Get top reviews for the drug\n",
        "    top_reviews = get_top_reviews_for_drug(train_data, drug_name)\n",
        "    if top_reviews.empty:\n",
        "        print(f\"No reviews found for the drug {drug_name}.\")\n",
        "        return\n",
        "\n",
        "    print(\"Top reviews for drug\", drug_name, \":\\n\", top_reviews)\n",
        "\n",
        "    # Extract topics\n",
        "    reviews_list = top_reviews['review'].tolist()\n",
        "    lda_words, nmf_words = extract_topics(reviews_list)\n",
        "\n",
        "    print(\"LDA topic words:\", lda_words)\n",
        "    print(\"NMF topic words:\", nmf_words)\n",
        "\n",
        "    # Highlight words in reviews\n",
        "    highlighted_reviews = [highlight_words(review, lda_words[0] + nmf_words[0]) for review in reviews_list]\n",
        "\n",
        "    print(\"Highlighted reviews:\")\n",
        "    for review in highlighted_reviews:\n",
        "        print(review)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro5pFhBPFMYM",
        "outputId": "751a31f8-1ed7-47af-ae62-275762a98715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the condition: left ventricular dysfunction\n",
            "Enter the drug name: valsartan\n",
            "Top drug names for condition left ventricular dysfunction : ['carvedilol', 'coreg', 'enalapril']\n",
            "Top reviews for drug valsartan :\n",
            "                                                   review  rating\n",
            "10055  i take diovan daily with norvasc 5mg  i have h...      10\n",
            "11788  i have been on this only since december 27 but...      10\n",
            "12432  i used several medications before my cardiolog...      10\n",
            "13118            0  effective for my high blood pressure      10\n",
            "17259  diovan was prescribed by my doctor nearly 10 y...      10\n",
            "LDA topic words: [['pressure', 'blood', 'high', 'effective', 'issues'], ['pressure', 'prescribed', 'used', 'diovan', 'years']]\n",
            "NMF topic words: [['years', 'effective', 'high', 'pressure', 'blood'], ['medicine', 'daily', 'relief', 'edema', 'issues']]\n",
            "Highlighted reviews:\n",
            "i take diovan daily with norvasc 5mg  i have had no <mark>issues</mark> with either medicine  i have had no <mark>issues</mark> with edema either which is a relief\n",
            "i have been on this only since december 27 but it has made a difference in my life  no more swollen ankles i sleep better at night and i have more energy  works great with no side effects\n",
            "i used several medications before my cardiologist prescribed diovan\n",
            "i have had wonderful results no side effects of any type and would suggest\n",
            "diovan to anyone needing their <mark><mark>blood</mark></mark> <mark><mark>pressure</mark></mark> controlled i consider this\n",
            "medication a miracle it has been for me i m 66 <mark>years</mark> old and have used it for\n",
            "7 <mark>years</mark>\n",
            "0  <mark><mark>effective</mark></mark> for my <mark><mark>high</mark></mark> <mark><mark>blood</mark></mark> <mark><mark>pressure</mark></mark>\n",
            "diovan was prescribed by my doctor nearly 10 <mark>years</mark> ago turns out both my parents also take it none of us have any side effects that we are aware of and it controls the hypertension effectively never been on any other <mark><mark>high</mark></mark> <mark><mark>blood</mark></mark> <mark><mark>pressure</mark></mark> treatment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer  # Import from tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences  # Import from tensorflow.keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "train_data = pd.read_csv('/content/drive/My Drive/drug_cleanedtrain.csv')\n",
        "test_data = pd.read_csv('/content/drive/My Drive/drug_cleanedtest.csv')\n",
        "\n",
        "# Preprocess text function\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''  # Handle non-string values\n",
        "    text = text.lower().strip()  # Lowercase and strip\n",
        "    text = re.sub(f'[{string.punctuation}]', '', text)  # Remove punctuation\n",
        "    text = re.sub('\\d+', '', text)  # Remove numbers\n",
        "    return text\n",
        "\n",
        "train_data['cleanedReview'] = train_data['review'].apply(preprocess_text)\n",
        "\n",
        "# Preprocess drug names to handle multiple names\n",
        "def preprocess_drug_names(drug_names):\n",
        "    return [name.strip() for name in drug_names.split(',')]\n",
        "\n",
        "# Create a mapping of conditions to drug names with frequencies\n",
        "def create_condition_to_drugs_mapping(df):\n",
        "    condition_to_drugs = {}\n",
        "    for condition, drugs in df.groupby('condition')['drugName']:\n",
        "        drug_counter = Counter()\n",
        "        for drug_list in drugs:\n",
        "            drug_counter.update(preprocess_drug_names(drug_list))\n",
        "        condition_to_drugs[condition.lower()] = drug_counter\n",
        "    return condition_to_drugs\n",
        "\n",
        "condition_to_drugs = create_condition_to_drugs_mapping(train_data)\n",
        "\n",
        "# Function to find drugs for a given condition\n",
        "def find_drugs_for_condition(condition, top_n=3):\n",
        "    condition = condition.lower().strip()  # Ensure consistency\n",
        "    drug_counter = condition_to_drugs.get(condition, Counter())\n",
        "\n",
        "    # Get the top N drugs based on frequency\n",
        "    top_drugs = drug_counter.most_common(top_n)\n",
        "    return [drug for drug, _ in top_drugs]\n",
        "\n",
        "# Function to get top reviews for a particular drug\n",
        "def get_top_reviews_for_drug(df, drug_name, top_n=5):\n",
        "    drug_reviews = df[df['drugName'].str.contains(drug_name, case=False, na=False)]\n",
        "    top_reviews = drug_reviews.nlargest(top_n, 'rating')[['review', 'rating']]\n",
        "    return top_reviews\n",
        "\n",
        "# Function to highlight words based on topics\n",
        "def highlight_words(text, words):\n",
        "    highlighted_text = text\n",
        "    for word in words:\n",
        "        highlighted_text = re.sub(f'\\\\b({word})\\\\b', r'<mark>\\1</mark>', highlighted_text, flags=re.IGNORECASE)\n",
        "    return highlighted_text\n",
        "\n",
        "# Function to extract topics using LDA and NMF\n",
        "def extract_topics(reviews, num_topics=2, num_words=5):\n",
        "    vectorizer = TfidfVectorizer(stop_words='english')\n",
        "    tfidf = vectorizer.fit_transform(reviews)\n",
        "\n",
        "    # LDA\n",
        "    lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
        "    lda.fit(tfidf)\n",
        "    lda_words = []\n",
        "    for topic in lda.components_:\n",
        "        lda_words.append([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-num_words:]])\n",
        "\n",
        "    # NMF\n",
        "    nmf = NMF(n_components=num_topics, random_state=42)\n",
        "    nmf.fit(tfidf)\n",
        "    nmf_words = []\n",
        "    for topic in nmf.components_:\n",
        "        nmf_words.append([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-num_words:]])\n",
        "\n",
        "    return lda_words, nmf_words\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Get input from user\n",
        "    condition = input(\"Enter the condition: \").strip()\n",
        "\n",
        "    # Find top drugs for the condition\n",
        "    top_drugs_for_condition = find_drugs_for_condition(condition)\n",
        "    if not top_drugs_for_condition:\n",
        "        print(f\"No drugs found for the condition {condition}.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Top drug names for condition {condition}: {top_drugs_for_condition}\")\n",
        "\n",
        "    for drug_name in top_drugs_for_condition:\n",
        "        # Get top reviews for the drug\n",
        "        top_reviews = get_top_reviews_for_drug(train_data, drug_name)\n",
        "        if top_reviews.empty:\n",
        "            print(f\"No reviews found for the drug {drug_name}.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Top reviews for drug {drug_name}:\\n\", top_reviews)\n",
        "\n",
        "        # Extract topics\n",
        "        reviews_list = top_reviews['review'].tolist()\n",
        "        lda_words, nmf_words = extract_topics(reviews_list)\n",
        "\n",
        "        print(f\"LDA topic words for {drug_name}:\", lda_words)\n",
        "        print(f\"NMF topic words for {drug_name}:\", nmf_words)\n",
        "\n",
        "        # Highlight words in reviews\n",
        "        highlighted_reviews = [highlight_words(review, lda_words[0] + nmf_words[0]) for review in reviews_list]\n",
        "\n",
        "        print(f\"Highlighted reviews for {drug_name}:\")\n",
        "        for review in highlighted_reviews:\n",
        "            print(review)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXmPF6AcGQ8d",
        "outputId": "ea74ba3e-0639-4f51-9ada-66e931e9ff52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Enter the condition: left ventricular dysfunction\n",
            "Top drug names for condition left ventricular dysfunction: ['carvedilol', 'coreg', 'enalapril']\n",
            "Top reviews for drug carvedilol:\n",
            "                                                   review  rating\n",
            "15563  i had congestive heart failure 6 years ago in ...      10\n",
            "20546  great when you start at a low dose then as doc...      10\n",
            "25301  although it has only been three months my qual...      10\n",
            "26551  my lvef was about 20 when i started on coreg f...      10\n",
            "30998  been on this for a year smallest dose twice a ...      10\n",
            "LDA topic words for carvedilol: [['years', 'thank', 'life', 'heart', 'coreg'], ['doctor', 'low', 'benefit', 'increases', 'dose']]\n",
            "NMF topic words for carvedilol: [['years', 'life', 'thank', 'heart', 'coreg'], ['low', 'increases', 'start', 'great', 'dose']]\n",
            "Highlighted reviews for carvedilol:\n",
            "i had congestive <mark><mark>heart</mark></mark> failure 6 <mark><mark>years</mark></mark> ago in my opinion <mark><mark>coreg</mark></mark> has saved my <mark><mark>life</mark></mark>   i <mark><mark>thank</mark></mark> god my cardiologist informed me of this drug\n",
            "great when you start at a low dose then as doctor increases dose i get less and less benefit\n",
            "\n",
            "although it has only been three months my quality of <mark><mark>life</mark></mark> is so much better than before an answer to my prayer to fix my <mark><mark>heart</mark></mark> <mark><mark>thank</mark></mark> you\n",
            "my lvef was about 20 when i started on <mark><mark>coreg</mark></mark> following a massive <mark><mark>heart</mark></mark> attack  i have used <mark><mark>coreg</mark></mark> since it first came on the market  i take 10 mg daily with no side effects  my lvef is now between 30 and 35  my <mark><mark>heart</mark></mark> attack was 21 <mark><mark>years</mark></mark> ago\n",
            "<mark><mark>coreg</mark></mark> has been a quotsilver bulletquot for me\n",
            "been on this for a year smallest dose twice a day no side effects had quadruple by pass no <mark><mark>heart</mark></mark> attack angina before surgery none since\n",
            "Top reviews for drug coreg:\n",
            "                                                   review  rating\n",
            "2044   my heart rate was speeding up to the point i c...      10\n",
            "24413  this medicine has saved my husbands life he we...      10\n",
            "44610  i had congestive heart failure 6 years ago in ...      10\n",
            "45573  i have been taking coreg for over 5 years and ...      10\n",
            "58183  i have had great results with coreg  my blood ...      10\n",
            "LDA topic words for coreg: [['informed', 'thank', 'god', 'cardiologist', 'heart'], ['heart', 'amp', 'pressure', 'rate', 'years']]\n",
            "NMF topic words for coreg: [['great', 'blood', 'heart', 'rate', 'pressure'], ['failure', 'saved', 'coreg', 'life', 'years']]\n",
            "Highlighted reviews for coreg:\n",
            "my <mark><mark>heart</mark></mark> <mark>rate</mark> was speeding up to the point i could feel my <mark><mark>heart</mark></mark> pounding in my chest it was more a problem at night when i would try to go to sleep <mark><mark>heart</mark></mark> was pounding and a wave <mark>pressure</mark> in my ears was keeping me from sleeping started medicine 35 mg twice daily and problem was in good control within one week i have a blockage left side 30 to 40 no problems since started medicine <mark>blood</mark> <mark>pressure</mark> is in real good control i continue ekg every 6 months \n",
            "this medicine has saved my husbands life he went in to <mark><mark>heart</mark></mark> failure amp had a ef of 10 in 21 with 16 days hospitalization amp discharged with this medication and a few more he has thrived and continues to do well today\n",
            "i had congestive <mark><mark>heart</mark></mark> failure 6 years ago in my opinion coreg has saved my life   i <mark>thank</mark> <mark>god</mark> my <mark>cardiologist</mark> <mark>informed</mark> me of this drug\n",
            "i have been taking coreg for over 5 years and it has been a lifesaver i am 79 years young and my quality of life is amazing    the only problem is the cost\n",
            "i have had <mark>great</mark> results with coreg  my <mark>blood</mark> <mark>pressure</mark> was high and <mark><mark>heart</mark></mark> <mark>rate</mark> and now my <mark>pressure</mark> is normal and <mark><mark>heart</mark></mark> <mark>rate</mark> is much slower\n",
            "Top reviews for drug enalapril:\n",
            "                                                    review  rating\n",
            "84726   enalapril has been shown to prevent the remode...      10\n",
            "157753                             this medicine is great      10\n",
            "30491   this medication worked great for me as far as ...       9\n",
            "63423   hypertension under control hours after taking ...       9\n",
            "121098  i rated this an 8 because i dont have anything...       8\n",
            "LDA topic words for enalapril: [['pressure', 'blood', 'good', 'great', 'medicine'], ['respect', 'years', 'heart', 'enalapril', 'medication']]\n",
            "NMF topic words for enalapril: [['days', 'hours', 'hypertension', 'great', 'medicine'], ['deteriorated', 'heart', 'years', 'enalapril', 'medication']]\n",
            "Highlighted reviews for enalapril:\n",
            "enalapril has been shown to prevent the remodeling of heart structure this is the most important drug that my  20 year old son takes with respect to delaying transplant his ventricular function has not deteriorated since starting enalapril  9 years ago and his cardiologist tells him to take this medication religiously\n",
            "this <mark><mark>medicine</mark></mark> is <mark><mark>great</mark></mark>\n",
            "this medication worked <mark><mark>great</mark></mark> for me as far as keeping my bp in check while i recovered from heart failure  i did have some mild coughing and dizziness if i got up too fast but nothing i couldnt handle  after being on this for 1 12 years i developed angioedema  swelling of lip and face  was immediately taken off the meds told to take some benadryl  the symptoms went away and i was put on a different medication\n",
            "<mark>hypertension</mark> under control <mark>hours</mark> after taking <mark><mark>medicine</mark></mark> only for  3 4 <mark>days</mark> so far so <mark>good</mark>\n",
            "i rated this an 8 because i dont have anything to compare it to but as far as reducing my <mark>blood</mark> <mark>pressure</mark> it works very well i can tell when i havent taken my daily dose because i get clammy and hot and all of the effects associated with high <mark>blood</mark> <mark>pressure</mark> when i do take it those effects subside and my <mark>blood</mark> <mark>pressure</mark> drastically drops to a normal level works <mark>good</mark> for me i am going to try my next month on lisinopril and see how that works out \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EL-eaa4gGRf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}