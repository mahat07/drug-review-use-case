{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BrasJF8FgMAr",
        "outputId": "8a91083a-75bc-4b7f-8c67-dc9b0d25fb5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_UEuvb84gMbS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PFbPHAesgVLH"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "train_file_path = '/content/drive/My Drive/archive drug/drugsComTrain_raw.csv'\n",
        "test_file_path = '/content/drive/My Drive/archive drug/drugsComTest_raw.csv'\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "data = pd.concat([train_data, test_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cVUUKkiVKj8F"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "data['review'] = data['review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a9snZreUgZ3_"
      },
      "outputs": [],
      "source": [
        "# Preprocess the data\n",
        "# Encode the ratings if they are not numerical\n",
        "label_encoder = LabelEncoder()\n",
        "data['rating'] = label_encoder.fit_transform(data['rating'])\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X = data['review']\n",
        "y = data['rating']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rC1tmSNXgcgy"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "# Initialize the vectorizers\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "count_vectorizer = CountVectorizer(max_features=5000)\n",
        "\n",
        "# Fit and transform the data\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
        "\n",
        "X_train_count = count_vectorizer.fit_transform(X_train)\n",
        "X_test_count = count_vectorizer.transform(X_test)\n",
        "\n",
        "# Combine the features\n",
        "X_train_combined = hstack([X_train_tfidf, X_train_count])\n",
        "X_test_combined = hstack([X_test_tfidf, X_test_count])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR1K51YFggGI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Convert sparse matrix to dense\n",
        "X_train_combined = X_train_combined.toarray()\n",
        "X_test_combined = X_test_combined.toarray()\n",
        "\n",
        "# Build the CNN model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(X_train_combined.shape[1],)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='linear'))  # For regression output\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_combined, y_train, epochs=5, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfK2P_ipJLn6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "predictions = model.predict(X_test_combined)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print(f\"Mean Absolute Error: {mae}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZIDNNg8gkLz"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/My Drive/drug/rating_predict.h5')\n",
        "\n",
        "# Save the TF-IDF Vectorizer\n",
        "with open('/content/drive/My Drive/drug/tfidf_vectorizer_rating.pkl', 'wb') as f:\n",
        "    joblib.dump(tfidf_vectorizer, f)\n",
        "\n",
        "# Save the CountVectorizer\n",
        "with open('/content/drive/My Drive/drug/count_vectorizer_rating.pkl', 'wb') as f:\n",
        "    joblib.dump(count_vectorizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrN8h5gTgkCa"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "predictions = model.predict(X_test_combined)\n",
        "\n",
        "# Show some predictions\n",
        "for i in range(5):\n",
        "    print(f\"Review: {X_test.iloc[i]}\")\n",
        "    print(f\"Actual Rating: {y_test.iloc[i]}\")\n",
        "    print(f\"Predicted Rating: {predictions[i][0]}\\n\")\n",
        "\n",
        "# Get user input and show prediction\n",
        "while True:\n",
        "    user_input = input(\"Enter a review to predict its rating (or 'exit' to quit): \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    # Load the vectorizers\n",
        "    with open('/content/drive/My Drive/drug/tfidf_vectorizer_rating.pkl', 'rb') as f:\n",
        "        tfidf_vectorizer = pickle.load(f)\n",
        "\n",
        "    with open('/content/drive/My Drive/drug/count_vectorizer_rating.pkl', 'rb') as f:\n",
        "        count_vectorizer = pickle.load(f)\n",
        "\n",
        "    # Feature extraction for user input\n",
        "    review_tfidf = tfidf_vectorizer.transform([user_input])\n",
        "    review_count = count_vectorizer.transform([user_input])\n",
        "    review_combined = hstack([review_tfidf, review_count]).toarray()\n",
        "\n",
        "    # Predict rating\n",
        "    prediction = model.predict(review_combined)\n",
        "    predicted_rating = prediction[0][0]\n",
        "\n",
        "    print(f\"Predicted Rating: {predicted_rating:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1IkfDqF--oz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}