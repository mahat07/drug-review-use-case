{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVaibImUwW_2",
        "outputId": "877a488d-1435-4f61-8ef4-22f0415f9e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtTmn04TwkCh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX9OOF6dw3EB"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "train_file_path = '/content/drive/My Drive/archive drug/drugsComTrain_raw.csv'\n",
        "test_file_path = '/content/drive/My Drive/archive drug/drugsComTest_raw.csv'\n",
        "train_data = pd.read_csv(train_file_path)\n",
        "test_data = pd.read_csv(test_file_path)\n",
        "df = pd.concat([train_data, test_data])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMSQRangw_or",
        "outputId": "da892fbb-6fe4-46c5-b080-9cdcb96949e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "21wCDgepw7lF"
      },
      "outputs": [],
      "source": [
        "# Preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lower case\n",
        "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "df['clean_review'] = df['review'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vG5gX3Mjw-MY"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vectorize the text data\n",
        "vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
        "X = vectorizer.fit_transform(df['clean_review'])\n",
        "\n",
        "# Fit LDA model\n",
        "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
        "lda_topics = lda_model.fit_transform(X)\n",
        "\n",
        "# Fit NMF model\n",
        "nmf_model = NMF(n_components=5, random_state=42)\n",
        "nmf_topics = nmf_model.fit_transform(X)\n",
        "\n",
        "# Extract feature names\n",
        "feature_names = vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWBHuo8IxSq0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to get the top words from each topic\n",
        "def get_top_words(model, feature_names, n_top_words=10):\n",
        "    top_words = {}\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_words[topic_idx] = [feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
        "    return top_words\n",
        "\n",
        "# Get top words from LDA and NMF\n",
        "lda_top_words = get_top_words(lda_model, feature_names)\n",
        "nmf_top_words = get_top_words(nmf_model, feature_names)\n",
        "\n",
        "# Combine top words from both models\n",
        "combined_top_words = {}\n",
        "for topic_idx in range(len(lda_top_words)):\n",
        "    combined_top_words[topic_idx] = list(set(lda_top_words[topic_idx] + nmf_top_words[topic_idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRdRJIc7xTYd",
        "outputId": "feac780d-e2a3-4974-af2d-af908f4506dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Helpful words: ['days', 'depression', 'period', 'feel', 'months', 'mg', 'day', 'ive', 'took', 'birth', 'month', 'control', 'life', 'sleep', 'works', 'years', 'taking', 'periods', 'im', 'hours', 'like', 'anxiety', 'medication', 'acne', 'time', 'bleeding', 'pain', 'pill', 'effects']\n"
          ]
        }
      ],
      "source": [
        "def get_helpful_words(review, vectorizer, lda_model, nmf_model, top_words):\n",
        "    # Preprocess the review\n",
        "    cleaned_review = preprocess_text(review)\n",
        "    review_vector = vectorizer.transform([cleaned_review])\n",
        "\n",
        "    # Get topic distributions\n",
        "    lda_distribution = lda_model.transform(review_vector)\n",
        "    nmf_distribution = nmf_model.transform(review_vector)\n",
        "\n",
        "    # Identify the most relevant topic\n",
        "    lda_topic = np.argmax(lda_distribution)\n",
        "    nmf_topic = np.argmax(nmf_distribution)\n",
        "\n",
        "    # Combine the words from the most relevant topics of LDA and NMF\n",
        "    helpful_words = set(top_words[lda_topic] + top_words[nmf_topic])\n",
        "\n",
        "    return list(helpful_words)\n",
        "\n",
        "# Example usage\n",
        "review = \"The medication worked well, but it caused some side effects.\"\n",
        "helpful_words = get_helpful_words(review, vectorizer, lda_model, nmf_model, combined_top_words)\n",
        "print(f\"Helpful words: {helpful_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAhzdWkkxVxv",
        "outputId": "f30e4501-a1dc-4aa9-e7dd-7625dffb2f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This drug was really very useful and it cured my condition\n",
            "Helpful words: ['days', 'depression', 'period', 'feel', 'months', 'mg', 'day', 'ive', 'took', 'birth', 'month', 'control', 'life', 'sleep', 'works', 'years', 'taking', 'periods', 'im', 'hours', 'like', 'anxiety', 'medication', 'acne', 'time', 'bleeding', 'pain', 'pill', 'effects']\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "review = input()\n",
        "helpful_words = get_helpful_words(review, vectorizer, lda_model, nmf_model, combined_top_words)\n",
        "print(f\"Helpful words: {helpful_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wRbhy5mxYX2",
        "outputId": "58082520-3bad-4e6c-f317-137b42da8263"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/drug/vectorizer.joblib']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "# Save the LDA model\n",
        "joblib.dump(lda_model, '/content/drive/My Drive/drug/lda_model.joblib')\n",
        "\n",
        "# Save the NMF model\n",
        "joblib.dump(nmf_model, '/content/drive/My Drive/drug/nmf_model.joblib')\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(vectorizer, '/content/drive/My Drive/drug/vectorizer.joblib')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}